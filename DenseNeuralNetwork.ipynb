{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8de0514",
   "metadata": {},
   "source": [
    "# Dense neural network\n",
    "A dense neural network, also known as a fully connected neural network, builds off of a single neuron model by connecting multiple neurons into layers, where each neuron is connected to every neuron in the adjacent layers. Like a single neuron, each neuron in a dense neural network takes an input vector, processes it through an activation function, and produces an output. Each layer of neurons receives input from the previous layer. By stacking multiple layers of neurons, a dense neural network can learn to recognize patterns far more complex than a single neuron can. In fact, the [universal approximation theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem) states that any reasonable function can be approximated by a dense neural network as long as one neuron layer has a nonlinear activation function.\n",
    "\n",
    "{IMAGE OF DNN}\n",
    "\n",
    "We will implement, from scratch, a dense neural network. We will train this dense neural network to recognize handwritten numerals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad0376",
   "metadata": {},
   "source": [
    "## MNIST handwritten digit database\n",
    "The MNIST handwritten digit databse is a collection of images that is widely used as a benchmark dataset for training and testing machine learning algorithms in image recognition. It contains 70,000 grayscale images of handwritten digits (0 to 9), each of which is a 28x28 greyscale pixel image. The dataset is divided into two subsets: 60,000 images for training and 10,000 images for testing. The images were collected from a variety of sources, including high school students and US Census Bureau employees.\n",
    "\n",
    "We can load the dataset via the `tensorflow.keras` package. `train_X` and `test_X` are stored as 3-dimensional tensors, where entry $i,j,k$ is the greyscale value of the pixel in row $j$, column $k$ of image sample $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "959899fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras \n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Show an example of an image\n",
    "plt.imshow(train_X[0], cmap=\"gray\")\n",
    "plt.title(\"Train_X image #0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af240cb",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "### Scaling\n",
    "The greyscale pixel values can have large variance, ranging between 0 and 255. Such large variance can lead to issues when training the weights and biases of our neurons. So we will scale all the greyscale values down to a range from 0 to 1 by dividing by 255.\n",
    "\n",
    "### Image flattening\n",
    "Additionally, the input layer to a dense neural network requires a vector as input. But our samples in `train_X` are 28-by-28 arrays. We can convert the arrays into vectors by flattening them: For a given array, stack the columns of the array into a single column vector. In this case, our input layer has size $28 \\times 28 = 784$.\n",
    "\n",
    "### One-hot encoding\n",
    "Each image is labeled with a 0-9 category to denote which numeral is depicted by the handwriting. We can use one-hot encoding to represent the labels. For each image, create a 10-length binary array indexed 0-9, where the array is all zeros except for the one located at the index associated with the image's numeral label. This also means our output layer has size 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1e1a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale pixel values from 0-255 to 0-1\n",
    "train_X = train_X / 255\n",
    "test_X = test_X / 255\n",
    "\n",
    "# Flatten training images and one-hot encode training labels\n",
    "flat_train_X = []\n",
    "onehot_train_y = []\n",
    "\n",
    "for x_array, y_label in zip(train_X, train_y):\n",
    "    flat_train_X.append(x_array.flatten().reshape(-1, 1))\n",
    "    y_vec = np.zeros((10, 1), dtype=bool)\n",
    "    y_vec[y_label][0] = 1\n",
    "    onehot_train_y.append(y_vec)\n",
    "\n",
    "# Flatten training images and one-hot encode training labels\n",
    "flat_test_X = []\n",
    "onehot_test_y = []\n",
    "\n",
    "for x_array, y_label in zip(test_X, test_y):\n",
    "    flat_test_X.append(x_array.flatten().reshape(-1, 1))\n",
    "    y_vec = np.zeros((10, 1), dtype=bool)\n",
    "    y_vec[y_label][0] = 1\n",
    "    onehot_test_y.append(y_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fba94f",
   "metadata": {},
   "source": [
    "## Network architecture\n",
    "Our dense neural network has 784-size input layer and 10-size output layer. There are $L$ total layers, where $L-2$ of these layers are the \"hidden\" intermediary layers between input and output. Arbitrarily, we will have two hidden layers, both of 60 neurons. (There is actually not a great way to decide how many hidden layers to employ until As for our single-neuron model, each of the neurons in our dense neural network must have a defined activation function and cost function.\n",
    "\n",
    "We will use the sigmoid function for our activation function: $\\sigma(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "The sigmoid function has known derivative: $\\frac{d}{dz} \\sigma(z) = \\sigma(z)(1 - \\sigma(z))$\n",
    "\n",
    "We will use the mean-squared error as our activation function: $C(W, b) = \\frac{1}{2}\\sum_{k=1}^{10}(\\hat{y}^{(i)}_k - y^{(i)}_k)^2$\n",
    "\n",
    "Training any neural network requires the following steps:\n",
    "1. Initialize the weights of biases of each neuron in each layer.\n",
    "2. Feedfoward phase to make a prediction.\n",
    "3. Calculate the cost function.\n",
    "4. Back-propogation with gradient descent to optimize weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3f608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "    Returns 1 / (1 + e^-z)\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def d_sigmoid(z):\n",
    "    '''\n",
    "    Returns derivative of sigmoid: sigmoid(z) * (1 - sigmoid(z))\n",
    "    '''\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79672da9",
   "metadata": {},
   "source": [
    "### Initialize weights\n",
    "We must initialize our weights and biases randomly. One way is just initialize the weights and biases using a uniform or normal random distribution. However, Dr. Davila recommends the following initialization. It utilizes a scalar factor he found in a research paper that supposedly speeds up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b31e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(layers=[784, 60, 60, 10]):\n",
    "    '''\n",
    "    Initializes weights and biases of each neuron in the dense neural network\n",
    "    INPUT\n",
    "        layers; list of natural numbers, where the ith entry describes the size of the ith neuron layer\n",
    "    RETURNS\n",
    "        W; list of numpy matrices, where the ith matrix contains the weights of neuron layer i\n",
    "        B; list of numpy matrices, where the ith matrix contains the biases of neuron layer i        \n",
    "    '''\n",
    "    # Initialize W, B with dummy elements at index 0. This is because layer 0 is the input layer and has no neurons.\n",
    "    # This maintains consistency so that python-list index i refers to the ith network layer.\n",
    "    W = [np.zeros((1,1))]\n",
    "    B = [np.zeros((1,1))]\n",
    "    \n",
    "    # Foreach layer, initialize weights and biases according to Dr. Davila's magic scaling factor\n",
    "    for lay in range(1, len(layers)):\n",
    "        w_temp = np.random.randn(layers[lay], layers[lay - 1]) * np.sqrt(2 / layers[lay - 1])\n",
    "        b_temp = np.random.randn(layers[lay], 1) * np.sqrt(2 / layers[lay - 1])\n",
    "        W.append(w_temp)\n",
    "        B.append(b_temp)\n",
    "    \n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfea86c",
   "metadata": {},
   "source": [
    "### Feedforward phase to make a prediction\n",
    "For each layer $l \\in \\{1, ..., L\\}$, let $W^l, b^l, z^l, a^l$ be the weights, biases, preactivation values, and postactivation values of the neurons in that layer. Note that the first layer, the input layer, has no weights/biases/preactivation value, and the postiactivation value is equal to the input signal vector. We can compute these as follows. Observe the parallels to the single-neuron model. The preactivation functions are a linear function on the postactivation values of the previous layer.\n",
    "\n",
    "\\begin{align}\n",
    "    z^l =& W^l a^{l-1} + b^l \\\\\n",
    "    a^l =& \\sigma(z^l)\n",
    "\\end{align}\n",
    "\n",
    "Starting by using the input layer as the inputs to layer 2, we can compute the postactivation values of the neuron layers in sequential order until we reach the output layer. The postactivation values of the output layer are the neural network's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef56bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_phase(W, B, input_vec, activation_function=sigmoid):\n",
    "    '''\n",
    "    Performs forward phase of the neural network described by weights W and biases B for input layer input_vec\n",
    "    INPUTS\n",
    "        W; list of numpy matrices, where the ith matrix contains the weights of neuron layer i\n",
    "        B; list of numpy matrices, where the ith matrix contains the biases of neuron layer i        \n",
    "        input_vec; input to neural network\n",
    "        activation_function; the activation function\n",
    "    RETURNS\n",
    "        the postactivation value of the output layer, as a numpy vector\n",
    "    '''\n",
    "    # List stores the preactivation values. Useful for backpropagation gradient descent.\n",
    "    # Dummy element at index 0. This is because layer 0 is the input layer and has no neurons.\n",
    "    # This maintains consistency so that python-list index i refers to the ith network layer.\n",
    "    preact = [np.zeros((1,1))]\n",
    "    \n",
    "    # List stores the postactivation values.Set layer 0 postactivation value to input vector\n",
    "    postact = [input_vec]\n",
    "    \n",
    "    # Compute postactivation output for each layer\n",
    "    for lay in range(1, len(W)):\n",
    "        \n",
    "        # Compute preactivation value\n",
    "        preact.append(np.matmul(W[lay], postact[-1]) + B[lay])\n",
    "        \n",
    "        # Compute postactivation value\n",
    "        postact.append(activation_function(preact[-1]))\n",
    "    \n",
    "    # Return output layer postactivation value\n",
    "    return postact, preact\n",
    "\n",
    "def predict(W, B, input_vec, activation_function=sigmoid):\n",
    "    '''\n",
    "    Makes a neural network prediction by selecting the index of the output layer postactivation vector with greatest value\n",
    "    INPUTS\n",
    "        W; list of numpy matrices, where the ith matrix contains the weights of neuron layer i\n",
    "        B; list of numpy matrices, where the ith matrix contains the biases of neuron layer i        \n",
    "        input_vec; input to neural network\n",
    "        activation_function; the activation function\n",
    "    OUTPUT\n",
    "        argmax index of output layer postactivation function\n",
    "    '''\n",
    "    postact_list, _ = forward_phase(W, B, input_vec, activation_function)\n",
    "    return np.argmax(postact_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30716ea",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "We select mean-squared error as our cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34815326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(predicted, actual):\n",
    "    '''\n",
    "    Returns the mean-squared error of a prediction\n",
    "    INPUT\n",
    "        predicted; list of predicted arrays\n",
    "        actual; list of actual arrays\n",
    "    RETURNS\n",
    "        the MSE\n",
    "    '''\n",
    "    return 1 / 2 * np.sum(np.square(predicted - actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab300b8",
   "metadata": {},
   "source": [
    "Just to demo our working neural network so far, let's see what we predict for the first image in the training set on our initial untrained weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "823f76c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction response vector:\n",
      "[[0.59730817]\n",
      " [0.1532687 ]\n",
      " [0.28919395]\n",
      " [0.51690415]\n",
      " [0.67791478]\n",
      " [0.57051982]\n",
      " [0.17621639]\n",
      " [0.85940319]\n",
      " [0.77654052]\n",
      " [0.70137855]]\n",
      "Prediction: 7\n",
      "MSE: 1.6198430814084541\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W, B = initialize_weights()\n",
    "postact_list, preact_list = forward_phase(W, B, flat_train_X[0])\n",
    "\n",
    "print(\"Prediction response vector:\")\n",
    "predicted = postact_list[-1]\n",
    "print(predicted)\n",
    "\n",
    "print(\"Prediction: \" + str(np.argmax(predicted)))\n",
    "\n",
    "actual = onehot_train_y[0]\n",
    "print(\"MSE: \" + str(mse(predicted, actual)))\n",
    "\n",
    "plt.imshow(train_X[0], cmap=\"gray\")\n",
    "plt.title(\"Train_X image #0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39dc848",
   "metadata": {},
   "source": [
    "### Back-propogation with gradient descent to optimize weights and biases\n",
    "Backpropagation is a technique for updating the weights and biases for a neural network. We will omit the proof of why backpropogation works because it is quite complex, but the [Wikipedia page](https://en.wikipedia.org/wiki/Backpropagation) has a good explanantion. The process is as follows so some learning rate $\\alpha$:\n",
    "1. $\\delta^L = \\nabla_a C \\otimes \\frac{d}{dz} \\sigma(z^L) = (a^L - y) \\otimes \\frac{d}{dz} \\sigma(z^L)$\n",
    "2. $\\forall l = L-1, ..., 1, \\delta^l = ((w ^ {l + 1}) ^ T \\delta ^ {l + 1}) \\otimes \\frac{d}{dz} \\sigma(z ^ l)$\n",
    "3. $\\forall l = 1, ..., L$:\n",
    " 1. $w^l \\gets w^l - \\alpha \\delta^l (a^{l-1}) ^ T$\n",
    " 2. $b^l \\gets b^l - \\alpha \\delta^l$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20a517b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropogation(W, B, actual, postact_list, preact_list, alpha=0.1, activation_gradient=d_sigmoid):\n",
    "    '''\n",
    "    Updates neurons' weights and biases via backpropagation gradient descent.\n",
    "    INPUT\n",
    "        W; list of numpy matrices, where the ith matrix contains the weights of neuron layer i\n",
    "        B; list of numpy matrices, where the ith matrix contains the biases of neuron layer i        \n",
    "        actual; the actual vector associated with this training sample\n",
    "        postact_list; list of numpy matrices, where the ith matrix contains the postactivation values computed by layer i\n",
    "        preact_list; list of numpy matrices, where the ith matrix contains the preactivation values computed by layer i\n",
    "        alpha; positive scalar learning rate\n",
    "        activation_gradient; the gradient of the activation function\n",
    "    OUTPUT\n",
    "        W and B after being updated by gradient descent\n",
    "    '''\n",
    "    deltas = [None] * len(W)\n",
    "    deltas[-1] = np.multiply((postact_list[-1] - actual), activation_gradient(preact_list[-1]))\n",
    "\n",
    "    for lay in range(len(W) - 2, 0, -1):\n",
    "        deltas[lay] = np.multiply(np.matmul(np.transpose(W[lay + 1]), deltas[lay + 1]),\n",
    "                                  activation_gradient(preact_list[lay]))\n",
    "    \n",
    "    for lay in range(1, len(W)):\n",
    "        W[lay] -= alpha * np.matmul(deltas[lay], np.transpose(postact_list[lay - 1]))\n",
    "        B[lay] -= alpha * deltas[lay]\n",
    "    \n",
    "    return W, B\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1232093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 60)\n",
      "(60, 1)\n"
     ]
    }
   ],
   "source": [
    "Wn, Bn = backpropogation(W, B, actual, postact_list, preact_list)\n",
    "print(Wn[2].shape)\n",
    "print(Bn[2].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_venv_inde577",
   "language": "python",
   "name": "pip_venv_inde577"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
