{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class for a single artificial neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SingleNeuron(ABC):\n",
    "    '''\n",
    "    Generic class for a single artificial neuron.\n",
    "    \n",
    "    ATTRIBUTES\n",
    "    \n",
    "    METHODS\n",
    "    '''\n",
    "    weights = None    # weights for preactivation function. 1-dimenional column array.\n",
    "    bias = None\n",
    "        \n",
    "    def predict(self, signal):\n",
    "        '''\n",
    "        Fires neuron. Computes preactivation value using weights and input signal. Then returns activation_function applied to the preactivation value.\n",
    "        INPUT\n",
    "            signal; the vector of data observations\n",
    "        RETURNS\n",
    "            scalar-valued preactivation value\n",
    "        '''\n",
    "        preactivation = np.matmul(signal, self.weights) + self.bias\n",
    "        return self.activation(preactivation)\n",
    "\n",
    "    \n",
    "    def train(self, X_train, y_train, n_epoch, learning_rate=None):\n",
    "        '''\n",
    "        '''\n",
    "        n_sample, n_features = X_train.shape\n",
    "        if self.weights is None:\n",
    "            self.weights = np.zeros((n_features, 1))\n",
    "        if self.bias is None:\n",
    "            self.bias = 0\n",
    "        epoch_cost = np.zeros((n_epoch, ))\n",
    "        prog = tqdm(range(n_epoch))\n",
    "        for epc in prog:\n",
    "            for ind in range(n_sample):\n",
    "                signal = X_train[ind, :].reshape((1, n_features))\n",
    "                predicted = self.predict(signal)[0]\n",
    "                actual = y_train[ind, 0]\n",
    "                self.update(actual, predicted, signal, learning_rate)\n",
    "                epoch_cost[epc] += self.cost_function(actual, predicted, signal)\n",
    "            prog.set_description(\"Cost: \" + str(round(epoch_cost[epc], 5)))\n",
    "            prog.update()\n",
    "        return epoch_cost\n",
    "    \n",
    "\n",
    "    @abstractmethod\n",
    "    def activation(self, preactivation):\n",
    "        '''\n",
    "        Given a preactivation scalar, returns the post-activation scalar output.\n",
    "        INPUT\n",
    "            preactivation; scalar-valued preactivation value\n",
    "        RETURNS\n",
    "            post-activation value, equivalent to the neuron's prediction\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update(self, actual, predicted, signal, learning_rate):\n",
    "        '''\n",
    "        '''\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def cost_function(self, actual, predicted, signal):\n",
    "        '''\n",
    "        '''\n",
    "        pass    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_venv_inde577",
   "language": "python",
   "name": "pip_venv_inde577"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
